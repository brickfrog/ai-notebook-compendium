{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNjcvhfjks4XI+FdxqTEhU9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fish Speech Fine Tune"
      ],
      "metadata": {
        "id": "5U6yH9-fBbKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just a convenience thing for following Fish's finetune in colab. I didn't have enough VRAM locally so I use this notebook for cloud training."
      ],
      "metadata": {
        "id": "eM_4xFk6GH19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Linux"
      ],
      "metadata": {
        "id": "lPQrf82iBUf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fAAScXAgA3LI",
        "outputId": "59529afc-9124-4dcc-de43-f274798686aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import locale\n",
        "\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prepare Env and Data\n",
        "\n",
        "TODO - use fish audio processing, right now just uploading pre-prepared, see: https://speech.fish.audio/finetune/\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "5tFViGFNBigH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fishaudio/fish-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k3JstHOZBFW2",
        "outputId": "453756a5-f73a-404c-fc26-61ac4debf46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fish-speech'...\n",
            "remote: Enumerating objects: 4824, done.\u001b[K\n",
            "remote: Counting objects: 100% (1399/1399), done.\u001b[K\n",
            "remote: Compressing objects: 100% (328/328), done.\u001b[K\n",
            "remote: Total 4824 (delta 1164), reused 1153 (delta 1057), pack-reused 3425 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4824/4824), 17.96 MiB | 1.97 MiB/s, done.\n",
            "Resolving deltas: 100% (3166/3166), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torch, etc. etc.\n",
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XG19XfuSHb1X",
        "outputId": "ada12df2-7c44-4067-853c-fe0a657a0182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libsox-dev ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyjNlV77Ncfe",
        "outputId": "358cabd3-e9ed-4964-b68f-e8dcb288d6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-all\n",
            "  libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3 libsox-fmt-oss libsox-fmt-pulse\n",
            "  libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libaudio2 libsndio6.1\n",
            "The following NEW packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0 libsox-dev\n",
            "  libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3 libsox-fmt-oss\n",
            "  libsox-fmt-pulse libsox3 libwavpack1\n",
            "0 upgraded, 16 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,053 kB of archives.\n",
            "After this operation, 4,061 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao-common all 1.2.2+20180113-1.1ubuntu3 [6,568 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao4 amd64 1.2.2+20180113-1.1ubuntu3 [35.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-ao amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,740 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-oss amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [9,424 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-pulse amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,732 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-all amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [5,016 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-dev amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [356 kB]\n",
            "Fetched 1,053 kB in 0s (3,272 kB/s)\n",
            "Selecting previously unselected package libao-common.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libao4:amd64.\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-dev:amd64.\n",
            "Preparing to unpack .../15-libsox-dev_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install fish-speech reqs\n",
        "!pip install -e /content/fish-speech/."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "z45FbJ2QHvBL",
        "outputId": "0059e2aa-3cad-4922-e45a-94df12c123f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fish-speech\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: transformers>=4.35.2 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (4.44.2)\n",
            "Collecting datasets==2.18.0 (from fish-speech==0.1.0)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning>=2.1.0 (from fish-speech==0.1.0)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting hydra-core>=1.3.2 (from fish-speech==0.1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: tensorboard>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (2.17.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (8.4.0)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (0.8.0)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (0.10.2.post1)\n",
            "Requirement already satisfied: rich>=13.5.3 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (13.9.2)\n",
            "Collecting gradio>=4.0.0 (from fish-speech==0.1.0)\n",
            "  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting wandb>=0.15.11 (from fish-speech==0.1.0)\n",
            "  Downloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from fish-speech==0.1.0) (1.64.1)\n",
            "Collecting kui>=1.6.0 (from fish-speech==0.1.0)\n",
            "  Downloading kui-1.8.1-py3-none-any.whl.metadata (984 bytes)\n",
            "Collecting uvicorn>=0.30.0 (from fish-speech==0.1.0)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting loguru>=0.6.0 (from fish-speech==0.1.0)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting loralib>=0.1.2 (from fish-speech==0.1.0)\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyrootutils>=1.0.4 (from fish-speech==0.1.0)\n",
            "  Downloading pyrootutils-1.0.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting vector-quantize-pytorch>=1.14.24 (from fish-speech==0.1.0)\n",
            "  Downloading vector_quantize_pytorch-1.18.5-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting resampy>=0.4.3 (from fish-speech==0.1.0)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting einx==0.2.2 (from einx[torch]==0.2.2->fish-speech==0.1.0)\n",
            "  Downloading einx-0.2.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting zstandard>=0.22.0 (from fish-speech==0.1.0)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pydub (from fish-speech==0.1.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting faster-whisper (from fish-speech==0.1.0)\n",
            "  Downloading faster_whisper-1.0.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting modelscope==1.17.1 (from fish-speech==0.1.0)\n",
            "  Downloading modelscope-1.17.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting funasr==1.1.5 (from fish-speech==0.1.0)\n",
            "  Downloading funasr-1.1.5-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting opencc-python-reimplemented==0.1.7 (from fish-speech==0.1.0)\n",
            "  Downloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting silero-vad (from fish-speech==0.1.0)\n",
            "  Downloading silero_vad-5.1.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting ormsgpack (from fish-speech==0.1.0)\n",
            "  Downloading ormsgpack-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (4.66.5)\n",
            "Collecting xxhash (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.13.3)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.5)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.1+cu121)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (1.13.1)\n",
            "Collecting jamo (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.12.1)\n",
            "Collecting kaldiio>=2.17.0 (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch-complex (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading torch_complex-0.4.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.42.1)\n",
            "Collecting pytorch-wpe (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.8.1)\n",
            "Collecting oss2 (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading oss2-2.19.0.tar.gz (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.1/298.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaconv (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorboardX (from funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from modelscope==1.17.1->fish-speech==0.1.0) (2.2.3)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->fish-speech==0.1.0) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.0 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub>=0.19.4 (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->fish-speech==0.1.0) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting orjson~=3.0 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->fish-speech==0.1.0) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->fish-speech==0.1.0) (2.9.2)\n",
            "Collecting python-multipart>=0.0.9 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->fish-speech==0.1.0) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->fish-speech==0.1.0) (4.12.2)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.0->gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->fish-speech==0.1.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->fish-speech==0.1.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting baize>=0.20.0 (from kui>=1.6.0->fish-speech==0.1.0)\n",
            "  Downloading baize-0.22.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.0.8)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting python-dotenv>=0.20.0 (from pyrootutils>=1.0.4->fish-speech==0.1.0)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.0.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.2->fish-speech==0.1.0) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.2->fish-speech==0.1.0) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.2->fish-speech==0.1.0) (0.19.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.30.0->fish-speech==0.1.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "INFO: pip is looking at multiple versions of vector-quantize-pytorch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting vector-quantize-pytorch>=1.14.24 (from fish-speech==0.1.0)\n",
            "  Downloading vector_quantize_pytorch-1.18.3-py3-none-any.whl.metadata (28 kB)\n",
            "  Downloading vector_quantize_pytorch-1.18.2-py3-none-any.whl.metadata (28 kB)\n",
            "  Downloading vector_quantize_pytorch-1.18.1-py3-none-any.whl.metadata (28 kB)\n",
            "  Downloading vector_quantize_pytorch-1.18.0-py3-none-any.whl.metadata (28 kB)\n",
            "  Downloading vector_quantize_pytorch-1.17.8-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.17.7-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.17.6-py3-none-any.whl.metadata (26 kB)\n",
            "INFO: pip is still looking at multiple versions of vector-quantize-pytorch to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading vector_quantize_pytorch-1.17.5-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.17.4-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.17.3-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.17.2-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.17.1-py3-none-any.whl.metadata (26 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading vector_quantize_pytorch-1.17.0-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.16.3-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.16.2-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.16.1-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.15.6-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.15.5-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.15.4-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading vector_quantize_pytorch-1.15.3-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.15.11->fish-speech==0.1.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.15.11->fish-speech==0.1.0)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.15.11->fish-speech==0.1.0)\n",
            "  Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting setproctitle (from wandb>=0.15.11->fish-speech==0.1.0)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting av<13,>=11.0 (from faster-whisper->fish-speech==0.1.0)\n",
            "  Downloading av-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper->fish-speech==0.1.0)\n",
            "  Downloading ctranslate2-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper->fish-speech==0.1.0)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: torchaudio>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from silero-vad->fish-speech==0.1.0) (2.4.1+cu121)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->fish-speech==0.1.0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->fish-speech==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->fish-speech==0.1.0) (1.2.2)\n",
            "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0->gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->fish-speech==0.1.0) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->fish-speech==0.1.0)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.3->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.10.1->fish-speech==0.1.0) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper->fish-speech==0.1.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper->fish-speech==0.1.0) (24.3.25)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio>=4.0.0->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio>=4.0.0->fish-speech==0.1.0) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.18.0->fish-speech==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.10.1->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->fish-speech==0.1.0) (1.5.4)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.3.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0) (43.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (2.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.18.0->fish-speech==0.1.0) (0.2.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper->fish-speech==0.1.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.2.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funasr-1.1.5-py3-none-any.whl (649 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m649.0/649.0 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.17.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.1.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.0-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kui-1.8.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading pyrootutils-1.0.4-py3-none-any.whl (5.8 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vector_quantize_pytorch-1.15.3-py3-none-any.whl (38 kB)\n",
            "Downloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faster_whisper-1.0.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.1/276.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading silero_vad-5.1.2-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading av-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading baize-0.22.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (743 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m743.0/743.0 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Downloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading sentry_sdk-2.16.0-py2.py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.8/313.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.40.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: fish-speech, antlr4-python3-runtime, jaconv, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building editable for fish-speech (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fish-speech: filename=fish_speech-0.1.0-0.editable-py3-none-any.whl size=11963 sha256=b3410e72f9f6d657e78f6e68563d1cabbbf9fbad4d6b30d0ec3adb6cb3732358\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ty4zt0tq/wheels/9c/40/e9/4fdf1f61da3e2597d501653a9ef5b58f23db01b6d0fe392ce1\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=dac7e859cd79147ec37ec6131ce2d178a5f4067cbd2da51efe57fb7d4ac9d660\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18228 sha256=2784a3b7fa92162683849bd708e0ba8be090f2abf08d634ae1e0b3fc6ac52b7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/95/99/94e8d7545125181756857f6b1fc085ed4e0811ad9be7321af7\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.19.0-py3-none-any.whl size=123848 sha256=57fc29f6b6babac708f3c00fc974664721a50d4fdff95c56fa394d30ab654af3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/a7/91/72a8bf5c60230015484cdc3e5d24635ecea87faea8908b75ec\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535316 sha256=7b2e1cd1ebac1187fc1c5dc5cd979e074e929dc6126f7413bee9526644239bbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/11/5e/08e7cb4e03a3e83b4862edd12d1143c8d3936a3dd57a3ee46d\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31405 sha256=59d067d3ebf26da9c223286fe7c11cd4c47f785e784b83dd7258f11552474fb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built fish-speech antlr4-python3-runtime jaconv oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: pydub, opencc-python-reimplemented, jamo, jaconv, crcmod, antlr4-python3-runtime, zstandard, xxhash, websockets, torch-complex, tomlkit, tensorboardX, smmap, setproctitle, sentry-sdk, semantic-version, ruff, pytorch-wpe, python-multipart, python-dotenv, pycryptodome, ormsgpack, orjson, omegaconf, markupsafe, loralib, loguru, lightning-utilities, kaldiio, jmespath, humanfriendly, h11, fsspec, ffmpy, docker-pycreds, dill, ctranslate2, baize, av, aiofiles, uvicorn, starlette, resampy, pyrootutils, multiprocess, modelscope, hydra-core, huggingface-hub, httpcore, gitdb, einx, coloredlogs, pynndescent, onnxruntime, kui, httpx, gitpython, fastapi, aliyun-python-sdk-core, wandb, vector-quantize-pytorch, umap-learn, torchmetrics, gradio-client, faster-whisper, aliyun-python-sdk-kms, silero-vad, pytorch-lightning, oss2, gradio, datasets, lightning, funasr, fish-speech\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.1\n",
            "    Uninstalling MarkupSafe-3.0.1:\n",
            "      Successfully uninstalled MarkupSafe-3.0.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 antlr4-python3-runtime-4.9.3 av-12.3.0 baize-0.22.2 coloredlogs-15.0.1 crcmod-1.7 ctranslate2-4.4.0 datasets-2.18.0 dill-0.3.8 docker-pycreds-0.4.0 einx-0.2.2 fastapi-0.115.2 faster-whisper-1.0.3 ffmpy-0.4.0 fish-speech-0.1.0 fsspec-2024.2.0 funasr-1.1.5 gitdb-4.0.11 gitpython-3.1.43 gradio-5.1.0 gradio-client-1.4.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.25.2 humanfriendly-10.0 hydra-core-1.3.2 jaconv-0.4.0 jamo-0.4.1 jmespath-0.10.0 kaldiio-2.18.0 kui-1.8.1 lightning-2.4.0 lightning-utilities-0.11.8 loguru-0.7.2 loralib-0.1.2 markupsafe-2.1.5 modelscope-1.17.1 multiprocess-0.70.16 omegaconf-2.3.0 onnxruntime-1.19.2 opencc-python-reimplemented-0.1.7 orjson-3.10.7 ormsgpack-1.5.0 oss2-2.19.0 pycryptodome-3.21.0 pydub-0.25.1 pynndescent-0.5.13 pyrootutils-1.0.4 python-dotenv-1.0.1 python-multipart-0.0.12 pytorch-lightning-2.4.0 pytorch-wpe-0.0.1 resampy-0.4.3 ruff-0.6.9 semantic-version-2.10.0 sentry-sdk-2.16.0 setproctitle-1.3.3 silero-vad-5.1.2 smmap-5.0.1 starlette-0.40.0 tensorboardX-2.6.2.2 tomlkit-0.12.0 torch-complex-0.4.4 torchmetrics-1.4.3 umap-learn-0.5.6 uvicorn-0.32.0 vector-quantize-pytorch-1.15.3 wandb-0.18.3 websockets-12.0 xxhash-3.5.0 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "53cfdf8d616e45e89a0bed5e0015f3e7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('/content/fish-speech/data/SPK1', exist_ok=True)\n",
        "os.chdir(\"/content/fish-speech/\")"
      ],
      "metadata": {
        "id": "WLLHSgahBy9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You then drag your archive/files with both the .mp3 and .lab files to the folder you created"
      ],
      "metadata": {
        "id": "4VC_9wMKFOgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/fish-speech/data/SPK1 && tar -xvf archive.tar > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "xovkKd5LFPqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Batch extraction of semantic tokens\n",
        "\n",
        "<hr>\n"
      ],
      "metadata": {
        "id": "zp4RzrBvJ8y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you have downloaded the VQGAN weights. If not, run the following command:\n",
        "\n"
      ],
      "metadata": {
        "id": "eHFCdjEnJVc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KmdXC9S8Iuig",
        "outputId": "8244e47f-6d04-401e-8a24-5d1ffb45d6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 8 files:   0% 0/8 [00:00<?, ?it/s]Downloading 'special_tokens_map.json' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/special_tokens_map.json.afaceb358180a0ba4d0ae9bd3b915b1ed43aa99d.incomplete'\n",
            "Downloading 'config.json' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/config.json.966eef0416c72fbe6b2938856c28707e3710b072.incomplete'\n",
            "Downloading 'README.md' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/README.md.c70e58a0f6ae54f86a898f60b1d6264956a74b54.incomplete'\n",
            "Downloading '.gitattributes' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/.gitattributes.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'tokenizer.json' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/tokenizer.json.1cc11817db7392d66ef4e47766ea7a887a9e4909.incomplete'\n",
            "Downloading 'tokenizer_config.json' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/tokenizer_config.json.3893b6bd0ce8c421066cb5895d88803a6d00fc33.incomplete'\n",
            "Downloading 'firefly-gan-vq-fsq-8x1024-21hz-generator.pth' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/firefly-gan-vq-fsq-8x1024-21hz-generator.pth.01b81dbf753224a156c3fe139b88bf0b9a0f54b11bee864f95e66511c3ccd754.incomplete'\n",
            "\n",
            "\rconfig.json:   0% 0.00/493 [00:00<?, ?B/s]\u001b[A\rconfig.json: 100% 493/493 [00:00<00:00, 1.99MB/s]\n",
            "\n",
            "\rREADME.md:   0% 0.00/1.39k [00:00<?, ?B/s]\u001b[A\rREADME.md: 100% 1.39k/1.39k [00:00<00:00, 14.7MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/config.json\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/README.md\n",
            "\n",
            "\rspecial_tokens_map.json:   0% 0.00/449 [00:00<?, ?B/s]\u001b[A\rspecial_tokens_map.json: 100% 449/449 [00:00<00:00, 3.47MB/s]\n",
            "\n",
            "\r.gitattributes:   0% 0.00/1.52k [00:00<?, ?B/s]\u001b[A\r.gitattributes: 100% 1.52k/1.52k [00:00<00:00, 13.7MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/special_tokens_map.json\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/.gitattributes\n",
            "Downloading 'model.pth' to 'checkpoints/fish-speech-1.4/.cache/huggingface/download/model.pth.5792b78b48d1f92d0b2cef8f07aad6b7ac19db2aff23a2054a5cce1d019ab4fb.incomplete'\n",
            "\rFetching 8 files:  12% 1/8 [00:00<00:01,  5.56it/s]\n",
            "\rtokenizer.json:   0% 0.00/1.60M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\rtokenizer_config.json:   0% 0.00/1.85k [00:00<?, ?B/s]\u001b[A\u001b[A\rtokenizer_config.json: 100% 1.85k/1.85k [00:00<00:00, 17.1MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/tokenizer_config.json\n",
            "\n",
            "\n",
            "\r(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   0% 0.00/189M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   0% 0.00/989M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "tokenizer.json: 100% 1.60M/1.60M [00:00<00:00, 15.8MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/tokenizer.json\n",
            "\n",
            "\n",
            "\n",
            "model.pth:   1% 10.5M/989M [00:00<00:13, 74.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   6% 10.5M/189M [00:00<00:02, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   3% 31.5M/989M [00:00<00:07, 120MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  17% 31.5M/189M [00:00<00:01, 112MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:   6% 62.9M/989M [00:00<00:05, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  33% 62.9M/189M [00:00<00:00, 167MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  10% 94.4M/989M [00:00<00:04, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  50% 94.4M/189M [00:00<00:00, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  13% 126M/989M [00:00<00:03, 228MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  67% 126M/189M [00:00<00:00, 219MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  16% 157M/989M [00:00<00:03, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  83% 157M/189M [00:00<00:00, 240MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth: 100% 189M/189M [00:00<00:00, 256MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth: 100% 189M/189M [00:00<00:00, 209MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\n",
            "Fetching 8 files:  50% 4/8 [00:01<00:01,  3.40it/s]\n",
            "\n",
            "\n",
            "model.pth:  22% 220M/989M [00:01<00:03, 246MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  25% 252M/989M [00:01<00:02, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  29% 283M/989M [00:01<00:02, 257MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  32% 315M/989M [00:01<00:02, 260MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  35% 346M/989M [00:01<00:02, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  38% 377M/989M [00:01<00:02, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  41% 409M/989M [00:01<00:02, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  45% 440M/989M [00:01<00:02, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  48% 472M/989M [00:01<00:01, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  51% 503M/989M [00:02<00:01, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  54% 535M/989M [00:02<00:01, 261MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  57% 566M/989M [00:02<00:01, 256MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  60% 598M/989M [00:02<00:01, 256MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  64% 629M/989M [00:02<00:01, 256MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  67% 661M/989M [00:02<00:01, 254MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  70% 692M/989M [00:02<00:01, 251MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  73% 724M/989M [00:02<00:01, 245MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  76% 755M/989M [00:03<00:00, 249MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  80% 786M/989M [00:03<00:00, 244MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  83% 818M/989M [00:03<00:00, 243MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  86% 849M/989M [00:03<00:00, 245MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  89% 881M/989M [00:03<00:00, 237MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  92% 912M/989M [00:03<00:00, 234MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth:  95% 944M/989M [00:03<00:00, 229MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.pth: 100% 989M/989M [00:04<00:00, 241MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.4/model.pth\n",
            "Fetching 8 files: 100% 8/8 [00:04<00:00,  1.84it/s]\n",
            "/content/fish-speech/checkpoints/fish-speech-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can then run the following command to extract semantic tokens:"
      ],
      "metadata": {
        "id": "68rS6KMCJq9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/vqgan/extract_vq.py data \\\n",
        "    --num-workers 1 --batch-size 16 \\\n",
        "    --config-name \"firefly_gan_vq\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n3BFjsssJbG9",
        "outputId": "2c5848e5-89e1-4e81-e500-633558f28991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-10-17 02:02:32.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m184\u001b[0m | RANK: 0 / 1 - \u001b[1mStarting worker\u001b[0m\n",
            "Found 301 files\n",
            "\u001b[32m2024-10-17 02:02:32.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m195\u001b[0m | RANK: 0 / 1 - \u001b[1mProcessing 301/301 files\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:457: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:642: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:162: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/content/fish-speech/tools/vqgan/extract_vq.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\n",
            "\u001b[32m2024-10-17 02:02:33.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m70\u001b[0m | RANK: 0 / 1 - \u001b[1mLoaded model\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/residual_fsq.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled = False):\n",
            "/usr/local/lib/python3.10/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:192: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with quantization_context():\n",
            "\u001b[32m2024-10-17 02:02:41.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m216\u001b[0m | RANK: 0 / 1 - \u001b[1mProcessed 160 files, 0.53 hours of audio, ETA: 0:00:09s\u001b[0m\n",
            "\u001b[32m2024-10-17 02:02:47.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m221\u001b[0m | RANK: 0 / 1 - \u001b[1mFinished processing 301 files, 0.99 hours of audio\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Pack the dataset into protobuf\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "If-8m47jJyDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/llama/build_dataset.py \\\n",
        "    --input \"data\" \\\n",
        "    --output \"data/protos\" \\\n",
        "    --text-extension .lab \\\n",
        "    --num-workers 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHxKh78tJo_q",
        "outputId": "9f9cb229-e4ea-4c0f-cf76-79351d3a1190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0it [00:00, ?it/s]\n",
            "\rLoading data: 0it [00:00, ?it/s]\u001b[A\rLoading data: 301it [00:00, 82343.17it/s]\n",
            "\n",
            "\rGrouping data:   0% 0/301 [00:00<?, ?it/s]\u001b[A\rGrouping data: 100% 301/301 [00:00<00:00, 31281.39it/s]\n",
            "\u001b[32m2024-10-17 02:03:04.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtask_generator_folder\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mFound 1 groups in data, ['data/SPK1']...\u001b[0m\n",
            "1it [00:00,  4.45it/s]\n",
            "\u001b[32m2024-10-17 02:03:04.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mFinished writing 1 shards to data/protos\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the command finishes executing, you should see the quantized-dataset-ft.protos file in the data directory."
      ],
      "metadata": {
        "id": "9oPR3qZ8KTv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Fine-tuning with LoRA\n"
      ],
      "metadata": {
        "id": "BYbBhZePKYeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, make sure you have downloaded the LLAMA weights. If not, run the following command:"
      ],
      "metadata": {
        "id": "imkNEpLhK2KO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download fishaudio/fish-speech-1.4 --local-dir checkpoints/fish-speech-1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCZuKZdZKUUC",
        "outputId": "921a9fa1-6a57-48a5-f670-bab438780d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 8 files:   0% 0/8 [00:00<?, ?it/s]\rFetching 8 files: 100% 8/8 [00:00<00:00, 6319.10it/s]\n",
            "/content/fish-speech/checkpoints/fish-speech-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, you can start the fine-tuning by running the following command:\n",
        "\n",
        "\n",
        "\n",
        "> Note: You can modify the training parameters such as batch_size, gradient_accumulation_steps, etc. to fit your GPU memory by modifying fish_speech/configs/text2semantic_finetune.yaml.\n"
      ],
      "metadata": {
        "id": "PGZ_QWmwK4bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python fish_speech/train.py --config-name text2semantic_finetune \\\n",
        "    project=$project \\\n",
        "    +lora@model.model.lora_config=r_8_alpha_16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X2ufvInK50P",
        "outputId": "bb792cc2-2630-48f0-8c57-759055b6916d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-10-17 02:03:27,931][__main__][INFO] - [rank: 0] Instantiating datamodule <fish_speech.datasets.semantic.SemanticDataModule>\n",
            "[2024-10-17 02:03:28,104][numexpr.utils][INFO] - NumExpr defaulting to 12 threads.\n",
            "[2024-10-17 02:03:28,252][datasets][INFO] - PyTorch version 2.4.1+cu121 available.\n",
            "[2024-10-17 02:03:28,253][datasets][INFO] - TensorFlow version 2.17.0 available.\n",
            "[2024-10-17 02:03:28,254][datasets][INFO] - JAX version 0.4.33 available.\n",
            "[2024-10-17 02:03:28,694][__main__][INFO] - [rank: 0] Instantiating model <fish_speech.models.text2semantic.lit_module.TextToSemantic>\n",
            "[2024-10-17 02:03:29,054][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] Override max_seq_len to 4096\n",
            "[2024-10-17 02:03:29,097][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] Loading model from checkpoints/fish-speech-1.4, config: DualARModelArgs(model_type='dual_ar', vocab_size=32000, n_layer=24, n_head=16, dim=1024, intermediate_size=4096, n_local_heads=2, head_dim=64, rope_base=1000000.0, norm_eps=1e-06, max_seq_len=4096, dropout=0.1, tie_word_embeddings=False, attention_qkv_bias=False, codebook_size=1024, num_codebooks=8, use_gradient_checkpointing=True, initializer_range=0.02, n_fast_layer=4)\n",
            "[2024-10-17 02:03:43,481][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] LoRA setup: LoraConfig(r=8, lora_alpha=16, lora_dropout=0.01)\n",
            "/content/fish-speech/fish_speech/models/text2semantic/llama.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  weights = torch.load(\n",
            "\u001b[32m2024-10-17 02:03:43.491\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.491\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.491\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.491\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.491\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.491\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.491\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.492\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.493\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.494\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.495\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.496\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.497\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.548\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.548\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.548\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.549\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.551\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.552\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.553\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.554\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.558\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.560\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.561\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.562\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.563\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.564\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 02:03:43.565\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_B\u001b[0m\n",
            "[2024-10-17 02:03:43,604][fish_speech.models.text2semantic.llama][INFO] - [rank: 0] Loaded weights with error: _IncompatibleKeys(missing_keys=['embeddings.lora_A', 'embeddings.lora_B', 'codebook_embeddings.lora_A', 'codebook_embeddings.lora_B', 'layers.0.attention.wqkv.lora_A', 'layers.0.attention.wqkv.lora_B', 'layers.0.attention.wo.lora_A', 'layers.0.attention.wo.lora_B', 'layers.0.feed_forward.w1.lora_A', 'layers.0.feed_forward.w1.lora_B', 'layers.0.feed_forward.w3.lora_A', 'layers.0.feed_forward.w3.lora_B', 'layers.0.feed_forward.w2.lora_A', 'layers.0.feed_forward.w2.lora_B', 'layers.1.attention.wqkv.lora_A', 'layers.1.attention.wqkv.lora_B', 'layers.1.attention.wo.lora_A', 'layers.1.attention.wo.lora_B', 'layers.1.feed_forward.w1.lora_A', 'layers.1.feed_forward.w1.lora_B', 'layers.1.feed_forward.w3.lora_A', 'layers.1.feed_forward.w3.lora_B', 'layers.1.feed_forward.w2.lora_A', 'layers.1.feed_forward.w2.lora_B', 'layers.2.attention.wqkv.lora_A', 'layers.2.attention.wqkv.lora_B', 'layers.2.attention.wo.lora_A', 'layers.2.attention.wo.lora_B', 'layers.2.feed_forward.w1.lora_A', 'layers.2.feed_forward.w1.lora_B', 'layers.2.feed_forward.w3.lora_A', 'layers.2.feed_forward.w3.lora_B', 'layers.2.feed_forward.w2.lora_A', 'layers.2.feed_forward.w2.lora_B', 'layers.3.attention.wqkv.lora_A', 'layers.3.attention.wqkv.lora_B', 'layers.3.attention.wo.lora_A', 'layers.3.attention.wo.lora_B', 'layers.3.feed_forward.w1.lora_A', 'layers.3.feed_forward.w1.lora_B', 'layers.3.feed_forward.w3.lora_A', 'layers.3.feed_forward.w3.lora_B', 'layers.3.feed_forward.w2.lora_A', 'layers.3.feed_forward.w2.lora_B', 'layers.4.attention.wqkv.lora_A', 'layers.4.attention.wqkv.lora_B', 'layers.4.attention.wo.lora_A', 'layers.4.attention.wo.lora_B', 'layers.4.feed_forward.w1.lora_A', 'layers.4.feed_forward.w1.lora_B', 'layers.4.feed_forward.w3.lora_A', 'layers.4.feed_forward.w3.lora_B', 'layers.4.feed_forward.w2.lora_A', 'layers.4.feed_forward.w2.lora_B', 'layers.5.attention.wqkv.lora_A', 'layers.5.attention.wqkv.lora_B', 'layers.5.attention.wo.lora_A', 'layers.5.attention.wo.lora_B', 'layers.5.feed_forward.w1.lora_A', 'layers.5.feed_forward.w1.lora_B', 'layers.5.feed_forward.w3.lora_A', 'layers.5.feed_forward.w3.lora_B', 'layers.5.feed_forward.w2.lora_A', 'layers.5.feed_forward.w2.lora_B', 'layers.6.attention.wqkv.lora_A', 'layers.6.attention.wqkv.lora_B', 'layers.6.attention.wo.lora_A', 'layers.6.attention.wo.lora_B', 'layers.6.feed_forward.w1.lora_A', 'layers.6.feed_forward.w1.lora_B', 'layers.6.feed_forward.w3.lora_A', 'layers.6.feed_forward.w3.lora_B', 'layers.6.feed_forward.w2.lora_A', 'layers.6.feed_forward.w2.lora_B', 'layers.7.attention.wqkv.lora_A', 'layers.7.attention.wqkv.lora_B', 'layers.7.attention.wo.lora_A', 'layers.7.attention.wo.lora_B', 'layers.7.feed_forward.w1.lora_A', 'layers.7.feed_forward.w1.lora_B', 'layers.7.feed_forward.w3.lora_A', 'layers.7.feed_forward.w3.lora_B', 'layers.7.feed_forward.w2.lora_A', 'layers.7.feed_forward.w2.lora_B', 'layers.8.attention.wqkv.lora_A', 'layers.8.attention.wqkv.lora_B', 'layers.8.attention.wo.lora_A', 'layers.8.attention.wo.lora_B', 'layers.8.feed_forward.w1.lora_A', 'layers.8.feed_forward.w1.lora_B', 'layers.8.feed_forward.w3.lora_A', 'layers.8.feed_forward.w3.lora_B', 'layers.8.feed_forward.w2.lora_A', 'layers.8.feed_forward.w2.lora_B', 'layers.9.attention.wqkv.lora_A', 'layers.9.attention.wqkv.lora_B', 'layers.9.attention.wo.lora_A', 'layers.9.attention.wo.lora_B', 'layers.9.feed_forward.w1.lora_A', 'layers.9.feed_forward.w1.lora_B', 'layers.9.feed_forward.w3.lora_A', 'layers.9.feed_forward.w3.lora_B', 'layers.9.feed_forward.w2.lora_A', 'layers.9.feed_forward.w2.lora_B', 'layers.10.attention.wqkv.lora_A', 'layers.10.attention.wqkv.lora_B', 'layers.10.attention.wo.lora_A', 'layers.10.attention.wo.lora_B', 'layers.10.feed_forward.w1.lora_A', 'layers.10.feed_forward.w1.lora_B', 'layers.10.feed_forward.w3.lora_A', 'layers.10.feed_forward.w3.lora_B', 'layers.10.feed_forward.w2.lora_A', 'layers.10.feed_forward.w2.lora_B', 'layers.11.attention.wqkv.lora_A', 'layers.11.attention.wqkv.lora_B', 'layers.11.attention.wo.lora_A', 'layers.11.attention.wo.lora_B', 'layers.11.feed_forward.w1.lora_A', 'layers.11.feed_forward.w1.lora_B', 'layers.11.feed_forward.w3.lora_A', 'layers.11.feed_forward.w3.lora_B', 'layers.11.feed_forward.w2.lora_A', 'layers.11.feed_forward.w2.lora_B', 'layers.12.attention.wqkv.lora_A', 'layers.12.attention.wqkv.lora_B', 'layers.12.attention.wo.lora_A', 'layers.12.attention.wo.lora_B', 'layers.12.feed_forward.w1.lora_A', 'layers.12.feed_forward.w1.lora_B', 'layers.12.feed_forward.w3.lora_A', 'layers.12.feed_forward.w3.lora_B', 'layers.12.feed_forward.w2.lora_A', 'layers.12.feed_forward.w2.lora_B', 'layers.13.attention.wqkv.lora_A', 'layers.13.attention.wqkv.lora_B', 'layers.13.attention.wo.lora_A', 'layers.13.attention.wo.lora_B', 'layers.13.feed_forward.w1.lora_A', 'layers.13.feed_forward.w1.lora_B', 'layers.13.feed_forward.w3.lora_A', 'layers.13.feed_forward.w3.lora_B', 'layers.13.feed_forward.w2.lora_A', 'layers.13.feed_forward.w2.lora_B', 'layers.14.attention.wqkv.lora_A', 'layers.14.attention.wqkv.lora_B', 'layers.14.attention.wo.lora_A', 'layers.14.attention.wo.lora_B', 'layers.14.feed_forward.w1.lora_A', 'layers.14.feed_forward.w1.lora_B', 'layers.14.feed_forward.w3.lora_A', 'layers.14.feed_forward.w3.lora_B', 'layers.14.feed_forward.w2.lora_A', 'layers.14.feed_forward.w2.lora_B', 'layers.15.attention.wqkv.lora_A', 'layers.15.attention.wqkv.lora_B', 'layers.15.attention.wo.lora_A', 'layers.15.attention.wo.lora_B', 'layers.15.feed_forward.w1.lora_A', 'layers.15.feed_forward.w1.lora_B', 'layers.15.feed_forward.w3.lora_A', 'layers.15.feed_forward.w3.lora_B', 'layers.15.feed_forward.w2.lora_A', 'layers.15.feed_forward.w2.lora_B', 'layers.16.attention.wqkv.lora_A', 'layers.16.attention.wqkv.lora_B', 'layers.16.attention.wo.lora_A', 'layers.16.attention.wo.lora_B', 'layers.16.feed_forward.w1.lora_A', 'layers.16.feed_forward.w1.lora_B', 'layers.16.feed_forward.w3.lora_A', 'layers.16.feed_forward.w3.lora_B', 'layers.16.feed_forward.w2.lora_A', 'layers.16.feed_forward.w2.lora_B', 'layers.17.attention.wqkv.lora_A', 'layers.17.attention.wqkv.lora_B', 'layers.17.attention.wo.lora_A', 'layers.17.attention.wo.lora_B', 'layers.17.feed_forward.w1.lora_A', 'layers.17.feed_forward.w1.lora_B', 'layers.17.feed_forward.w3.lora_A', 'layers.17.feed_forward.w3.lora_B', 'layers.17.feed_forward.w2.lora_A', 'layers.17.feed_forward.w2.lora_B', 'layers.18.attention.wqkv.lora_A', 'layers.18.attention.wqkv.lora_B', 'layers.18.attention.wo.lora_A', 'layers.18.attention.wo.lora_B', 'layers.18.feed_forward.w1.lora_A', 'layers.18.feed_forward.w1.lora_B', 'layers.18.feed_forward.w3.lora_A', 'layers.18.feed_forward.w3.lora_B', 'layers.18.feed_forward.w2.lora_A', 'layers.18.feed_forward.w2.lora_B', 'layers.19.attention.wqkv.lora_A', 'layers.19.attention.wqkv.lora_B', 'layers.19.attention.wo.lora_A', 'layers.19.attention.wo.lora_B', 'layers.19.feed_forward.w1.lora_A', 'layers.19.feed_forward.w1.lora_B', 'layers.19.feed_forward.w3.lora_A', 'layers.19.feed_forward.w3.lora_B', 'layers.19.feed_forward.w2.lora_A', 'layers.19.feed_forward.w2.lora_B', 'layers.20.attention.wqkv.lora_A', 'layers.20.attention.wqkv.lora_B', 'layers.20.attention.wo.lora_A', 'layers.20.attention.wo.lora_B', 'layers.20.feed_forward.w1.lora_A', 'layers.20.feed_forward.w1.lora_B', 'layers.20.feed_forward.w3.lora_A', 'layers.20.feed_forward.w3.lora_B', 'layers.20.feed_forward.w2.lora_A', 'layers.20.feed_forward.w2.lora_B', 'layers.21.attention.wqkv.lora_A', 'layers.21.attention.wqkv.lora_B', 'layers.21.attention.wo.lora_A', 'layers.21.attention.wo.lora_B', 'layers.21.feed_forward.w1.lora_A', 'layers.21.feed_forward.w1.lora_B', 'layers.21.feed_forward.w3.lora_A', 'layers.21.feed_forward.w3.lora_B', 'layers.21.feed_forward.w2.lora_A', 'layers.21.feed_forward.w2.lora_B', 'layers.22.attention.wqkv.lora_A', 'layers.22.attention.wqkv.lora_B', 'layers.22.attention.wo.lora_A', 'layers.22.attention.wo.lora_B', 'layers.22.feed_forward.w1.lora_A', 'layers.22.feed_forward.w1.lora_B', 'layers.22.feed_forward.w3.lora_A', 'layers.22.feed_forward.w3.lora_B', 'layers.22.feed_forward.w2.lora_A', 'layers.22.feed_forward.w2.lora_B', 'layers.23.attention.wqkv.lora_A', 'layers.23.attention.wqkv.lora_B', 'layers.23.attention.wo.lora_A', 'layers.23.attention.wo.lora_B', 'layers.23.feed_forward.w1.lora_A', 'layers.23.feed_forward.w1.lora_B', 'layers.23.feed_forward.w3.lora_A', 'layers.23.feed_forward.w3.lora_B', 'layers.23.feed_forward.w2.lora_A', 'layers.23.feed_forward.w2.lora_B', 'output.lora_A', 'output.lora_B', 'fast_embeddings.lora_A', 'fast_embeddings.lora_B', 'fast_layers.0.attention.wqkv.lora_A', 'fast_layers.0.attention.wqkv.lora_B', 'fast_layers.0.attention.wo.lora_A', 'fast_layers.0.attention.wo.lora_B', 'fast_layers.0.feed_forward.w1.lora_A', 'fast_layers.0.feed_forward.w1.lora_B', 'fast_layers.0.feed_forward.w3.lora_A', 'fast_layers.0.feed_forward.w3.lora_B', 'fast_layers.0.feed_forward.w2.lora_A', 'fast_layers.0.feed_forward.w2.lora_B', 'fast_layers.1.attention.wqkv.lora_A', 'fast_layers.1.attention.wqkv.lora_B', 'fast_layers.1.attention.wo.lora_A', 'fast_layers.1.attention.wo.lora_B', 'fast_layers.1.feed_forward.w1.lora_A', 'fast_layers.1.feed_forward.w1.lora_B', 'fast_layers.1.feed_forward.w3.lora_A', 'fast_layers.1.feed_forward.w3.lora_B', 'fast_layers.1.feed_forward.w2.lora_A', 'fast_layers.1.feed_forward.w2.lora_B', 'fast_layers.2.attention.wqkv.lora_A', 'fast_layers.2.attention.wqkv.lora_B', 'fast_layers.2.attention.wo.lora_A', 'fast_layers.2.attention.wo.lora_B', 'fast_layers.2.feed_forward.w1.lora_A', 'fast_layers.2.feed_forward.w1.lora_B', 'fast_layers.2.feed_forward.w3.lora_A', 'fast_layers.2.feed_forward.w3.lora_B', 'fast_layers.2.feed_forward.w2.lora_A', 'fast_layers.2.feed_forward.w2.lora_B', 'fast_layers.3.attention.wqkv.lora_A', 'fast_layers.3.attention.wqkv.lora_B', 'fast_layers.3.attention.wo.lora_A', 'fast_layers.3.attention.wo.lora_B', 'fast_layers.3.feed_forward.w1.lora_A', 'fast_layers.3.feed_forward.w1.lora_B', 'fast_layers.3.feed_forward.w3.lora_A', 'fast_layers.3.feed_forward.w3.lora_B', 'fast_layers.3.feed_forward.w2.lora_A', 'fast_layers.3.feed_forward.w2.lora_B', 'fast_output.lora_A', 'fast_output.lora_B'], unexpected_keys=[])\n",
            "[2024-10-17 02:03:43,607][__main__][INFO] - [rank: 0] Instantiating callbacks...\n",
            "[2024-10-17 02:03:43,607][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>\n",
            "[2024-10-17 02:03:43,611][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelSummary>\n",
            "[2024-10-17 02:03:43,612][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.LearningRateMonitor>\n",
            "[2024-10-17 02:03:43,612][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating callback <fish_speech.callbacks.GradNormMonitor>\n",
            "[2024-10-17 02:03:43,615][__main__][INFO] - [rank: 0] Instantiating loggers...\n",
            "[2024-10-17 02:03:43,615][fish_speech.utils.instantiators][INFO] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>\n",
            "[2024-10-17 02:03:43,618][__main__][INFO] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>\n",
            "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "[2024-10-17 02:03:43,668][__main__][INFO] - [rank: 0] Logging hyperparameters!\n",
            "2024-10-17 02:03:44.071752: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-17 02:03:44.087470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-17 02:03:44.105488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-17 02:03:44.110738: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-17 02:03:44.124026: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-17 02:03:45.376168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-10-17 02:03:46,283][__main__][INFO] - [rank: 0] Starting training!\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "[2024-10-17 02:03:47,262][fish_speech.models.text2semantic.lit_module][INFO] - [rank: 0] Set weight decay: 0 for 432 parameters\n",
            "[2024-10-17 02:03:47,262][fish_speech.models.text2semantic.lit_module][INFO] - [rank: 0] Set weight decay: 0.0 for 61 parameters\n",
            "\n",
            "  | Name                      | Type              | Params | Mode \n",
            "------------------------------------------------------------------------\n",
            "0 | model                     | DualARTransformer | 499 M  | train\n",
            "1 | model.embeddings          | Embedding         | 33.0 M | train\n",
            "2 | model.codebook_embeddings | Embedding         | 8.5 M  | train\n",
            "3 | model.layers              | ModuleList        | 362 M  | train\n",
            "4 | model.norm                | RMSNorm           | 1.0 K  | train\n",
            "5 | model.output              | Linear            | 33.0 M | train\n",
            "6 | model.fast_embeddings     | Embedding         | 1.1 M  | train\n",
            "7 | model.fast_layers         | ModuleList        | 60.4 M | train\n",
            "8 | model.fast_norm           | RMSNorm           | 1.0 K  | train\n",
            "9 | model.fast_output         | Linear            | 1.1 M  | train\n",
            "------------------------------------------------------------------------\n",
            "5.1 M     Trainable params\n",
            "494 M     Non-trainable params\n",
            "499 M     Total params\n",
            "1,998.053 Total estimated model params size (MB)\n",
            "432       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s][2024-10-17 02:03:47,448][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 2 / 1 files\n",
            "[2024-10-17 02:03:47,449][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 1 / 1 files\n",
            "[2024-10-17 02:03:47,461][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 1 groups of data\n",
            "[2024-10-17 02:03:47,464][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 1 / 1 files\n",
            "[2024-10-17 02:03:47,470][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 1 / 1 files\n",
            "[2024-10-17 02:03:47,470][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 2 groups of data\n",
            "[2024-10-17 02:03:47,479][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 1 groups of data\n",
            "[2024-10-17 02:03:47,480][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 1 groups of data\n",
            "[2024-10-17 02:03:50,546][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 2 / 1 files\n",
            "[2024-10-17 02:03:50,546][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 1 / 1 files\n",
            "[2024-10-17 02:03:50,560][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 1 groups of data\n",
            "[2024-10-17 02:03:50,562][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 1 / 1 files\n",
            "[2024-10-17 02:03:50,568][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 2 groups of data\n",
            "[2024-10-17 02:03:50,568][fish_speech.datasets.semantic][INFO] - [rank: 0] Reading 1 / 1 files\n",
            "[2024-10-17 02:03:50,573][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 1 groups of data\n",
            "[2024-10-17 02:03:50,579][fish_speech.datasets.semantic][INFO] - [rank: 0] Read total 1 groups of data\n",
            "Epoch 0: |          | 0/? [00:00<?, ?it/s] /usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "Epoch 0: |          | 100/? [06:45<00:00,  0.25it/s, v_num=0, train/loss=4.440, train/top_5_accuracy=0.367]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.32it/s]\u001b[A\n",
            "Epoch 0: |          | 200/? [13:39<00:00,  0.24it/s, v_num=0, train/loss=3.940, train/top_5_accuracy=0.408, val/loss=4.430, val/top_5_accuracy=0.362]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.30it/s]\u001b[A\n",
            "Epoch 0: |          | 300/? [20:34<00:00,  0.24it/s, v_num=0, train/loss=3.690, train/top_5_accuracy=0.424, val/loss=4.000, val/top_5_accuracy=0.398]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.31it/s]\u001b[A\n",
            "Epoch 0: |          | 400/? [27:27<00:00,  0.24it/s, v_num=0, train/loss=3.720, train/top_5_accuracy=0.418, val/loss=3.650, val/top_5_accuracy=0.428]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.29it/s]\u001b[A\n",
            "Epoch 0: |          | 500/? [34:20<00:00,  0.24it/s, v_num=0, train/loss=3.300, train/top_5_accuracy=0.480, val/loss=3.410, val/top_5_accuracy=0.459]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.34it/s]\u001b[A\n",
            "Epoch 0: |          | 600/? [41:16<00:00,  0.24it/s, v_num=0, train/loss=3.220, train/top_5_accuracy=0.494, val/loss=3.350, val/top_5_accuracy=0.473]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.32it/s]\u001b[A\n",
            "Epoch 0: |          | 700/? [48:12<00:00,  0.24it/s, v_num=0, train/loss=3.120, train/top_5_accuracy=0.516, val/loss=3.210, val/top_5_accuracy=0.501]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.31it/s]\u001b[A\n",
            "Epoch 0: |          | 800/? [55:07<00:00,  0.24it/s, v_num=0, train/loss=3.140, train/top_5_accuracy=0.520, val/loss=3.100, val/top_5_accuracy=0.526]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.30it/s]\u001b[A\n",
            "Epoch 0: |          | 900/? [1:02:02<00:00,  0.24it/s, v_num=0, train/loss=3.090, train/top_5_accuracy=0.527, val/loss=3.010, val/top_5_accuracy=0.548]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.31it/s]\u001b[A\n",
            "Epoch 0: |          | 1000/? [1:08:55<00:00,  0.24it/s, v_num=0, train/loss=3.050, train/top_5_accuracy=0.539, val/loss=2.950, val/top_5_accuracy=0.562]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/10 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 10/10 [00:07<00:00,  1.30it/s]\u001b[A\n",
            "Epoch 0: |          | 1000/? [1:09:03<00:00,  0.24it/s, v_num=0, train/loss=3.050, train/top_5_accuracy=0.539, val/loss=2.870, val/top_5_accuracy=0.579]`Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "Epoch 0: |          | 1000/? [1:09:03<00:00,  0.24it/s, v_num=0, train/loss=3.050, train/top_5_accuracy=0.539, val/loss=2.870, val/top_5_accuracy=0.579]\n",
            "[2024-10-17 03:12:56,180][fish_speech.utils.utils][INFO] - [rank: 0] Output dir: results/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, you need to convert the LoRA weights to regular weights before performing inference."
      ],
      "metadata": {
        "id": "VNl5IGG_LTtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls results/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwIACZjGgp2I",
        "outputId": "c6dcbc99-6576-40f6-a3d6-a0d7e4c8e844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step_000000600.ckpt  step_000000800.ckpt  step_000001000.ckpt\n",
            "step_000000700.ckpt  step_000000900.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to match with one of these files, we suggest using the earliest checkpoint that meets your requirements, as they often perform better on out-of-distribution (OOD) data."
      ],
      "metadata": {
        "id": "dFu22_IhgoYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/llama/merge_lora.py \\\n",
        "    --lora-config r_8_alpha_16 \\\n",
        "    --base-weight checkpoints/fish-speech-1.4 \\\n",
        "    --lora-weight results/checkpoints/step_000000600.ckpt \\\n",
        "    --output checkpoints/fish-speech-1.4-yth-lora/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDAweHnrLS6G",
        "outputId": "d3e8f763-2041-4919-c7a6-b5a509192594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-10-17 03:24:31.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mMerging checkpoints/fish-speech-1.4 and results/checkpoints/step_000000600.ckpt into checkpoints/fish-speech-1.4-yth-lora with r_8_alpha_16\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:31.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoaded lora model with config LoraConfig(r=8, lora_alpha=16, lora_dropout=0.01)\u001b[0m\n",
            "/content/fish-speech/fish_speech/models/text2semantic/llama.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  weights = torch.load(\n",
            "\u001b[32m2024-10-17 03:24:46.094\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.094\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.094\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.094\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.096\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.097\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.098\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.099\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.100\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.143\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.143\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.147\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.148\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.149\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.150\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.152\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.153\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.154\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.156\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.158\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.159\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_A\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_B\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mLoaded llama model\u001b[0m\n",
            "/content/fish-speech/tools/llama/merge_lora.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lora_state_dict = torch.load(lora_weight, map_location=\"cpu\")\n",
            "\u001b[32m2024-10-17 03:24:46.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mFound 203 keys in llama model\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound 290 keys in lora model\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:46.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mMerged model loaded\u001b[0m\n",
            "\u001b[32m2024-10-17 03:24:49.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaved merged model to checkpoints/fish-speech-1.4-yth-lora, validating\u001b[0m\n",
            "/content/fish-speech/tools/llama/merge_lora.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  new_state_dict = torch.load(output / \"model.pth\", map_location=\"cpu\")\n",
            "\u001b[32m2024-10-17 03:24:49.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mMerged model is different from the original model, check passed\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls results/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1tWBtlpd-_K",
        "outputId": "df7deac0-a8f2-4c34-9c73-d370a539814e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step_000000600.ckpt  step_000000800.ckpt  step_000001000.ckpt\n",
            "step_000000700.ckpt  step_000000900.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -czvf fish-speech-1.4-yth.tar.gz checkpoints/fish-speech-1.4-yth-lora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7KiOkO5ifpH",
        "outputId": "910f4218-c530-4821-e7a4-25cbe51b7ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints/fish-speech-1.4-yth-lora/\n",
            "checkpoints/fish-speech-1.4-yth-lora/model.pth\n",
            "checkpoints/fish-speech-1.4-yth-lora/tokenizer.json\n",
            "checkpoints/fish-speech-1.4-yth-lora/config.json\n",
            "checkpoints/fish-speech-1.4-yth-lora/tokenizer_config.json\n",
            "checkpoints/fish-speech-1.4-yth-lora/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORa8zBtVij9z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}